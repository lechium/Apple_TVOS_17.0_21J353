//
//     Generated by classdump-c 4.2.0 (64 bit).
//
//  Copyright (C) 1997-2019 Steve Nygard. Updated in 2022 by Kevin Bradley.
//

#import <objc/NSObject.h>

@class CSAsset, CSAudioRecordContext, CSEnhancedEndpointer, CSServerEndpointFeatures, NSDate, NSDictionary, NSMutableArray, NSString, OSDFeatures, _EAREndpointer;
@protocol CSEndpointAnalyzerDelegate, CSEndpointAnalyzerImplDelegate, OS_dispatch_queue;

@interface CSHybridEndpointer : NSObject
{
    _Bool _saveSamplesSeenInReset;	// 8 = 0x8
    _Bool _canProcessCurrentRequest;	// 9 = 0x9
    _Bool _epResult;	// 10 = 0xa
    _Bool _didReceiveServerFeatures;	// 11 = 0xb
    _Bool _useDefaultServerFeaturesOnClientLag;	// 12 = 0xc
    _Bool _didCommunicateEndpoint;	// 13 = 0xd
    _Bool _didNotifyTwoShot;	// 14 = 0xe
    _Bool _speechEndpointDetected;	// 15 = 0xf
    _Bool _didTimestampFirstAudioPacket;	// 16 = 0x10
    _Bool _isAnchorTimeBuffered;	// 17 = 0x11
    _Bool _isRequestTimeout;	// 18 = 0x12
    _Bool _isASRFeatureFromServer;	// 19 = 0x13
    _Bool _recordingDidStop;	// 20 = 0x14
    _Bool _didDetectSpeech;	// 21 = 0x15
    _Bool _enhancedEndpointerDefaultResult;	// 22 = 0x16
    _Bool _enhancedEndpointerRelaxedResult;	// 23 = 0x17
    _Bool _didReceiveRCFeatures;	// 24 = 0x18
    _Bool _hasAcceptedEagerResult;	// 25 = 0x19
    float _lastEndpointPosterior;	// 28 = 0x1c
    id <CSEndpointAnalyzerDelegate> _delegate;	// 32 = 0x20
    id <CSEndpointAnalyzerImplDelegate> _implDelegate;	// 40 = 0x28
    unsigned long long _activeChannel;	// 48 = 0x30
    NSString *_mhId;	// 56 = 0x38
    long long _endpointStyle;	// 64 = 0x40
    long long _endpointMode;	// 72 = 0x48
    double _startWaitTime;	// 80 = 0x50
    double _endWaitTime;	// 88 = 0x58
    double _interspeechWaitTime;	// 96 = 0x60
    double _delay;	// 104 = 0x68
    double _automaticEndpointingSuspensionEndTime;	// 112 = 0x70
    double _minimumDurationForEndpointer;	// 120 = 0x78
    CSAsset *_currentAsset;	// 128 = 0x80
    OSDFeatures *_osdFeaturesAtEndpoint;	// 136 = 0x88
    _EAREndpointer *_hybridClassifier;	// 144 = 0x90
    NSString *_endpointerModelVersion;	// 152 = 0x98
    NSObject<OS_dispatch_queue> *_serverFeaturesQueue;	// 160 = 0xa0
    CSServerEndpointFeatures *_lastKnownServerEPFeatures;	// 168 = 0xa8
    OSDFeatures *_lastKnownOSDFeatures;	// 176 = 0xb0
    CSServerEndpointFeatures *_lastKnownRCFeatures;	// 184 = 0xb8
    NSMutableArray *_serverFeatureLatencies;	// 192 = 0xc0
    double _lastKnowServerFeaturesLatency;	// 200 = 0xc8
    double _lastKnownRCServerFeaturesLatency;	// 208 = 0xd0
    double _serverFeaturesWarmupLatency;	// 216 = 0xd8
    NSDate *_lastServerFeatureTimestamp;	// 224 = 0xe0
    double _clientLagThresholdMs;	// 232 = 0xe8
    double _clampedSFLatencyMsForClientLag;	// 240 = 0xf0
    unsigned long long _extraDelayFrequency;	// 248 = 0xf8
    NSDictionary *_taskThresholdMap;	// 256 = 0x100
    NSObject<OS_dispatch_queue> *_hybridClassifierQueue;	// 264 = 0x108
    double _lastReportedEndpointTimeMs;	// 272 = 0x110
    double _processedAudioInSeconds;	// 280 = 0x118
    NSObject<OS_dispatch_queue> *_stateSerialQueue;	// 288 = 0x120
    unsigned long long _currentRequestSampleRate;	// 296 = 0x128
    double _vtExtraAudioAtStartInMs;	// 304 = 0x130
    unsigned long long _vtEndInSampleCount;	// 312 = 0x138
    double _hepAudioOriginInMs;	// 320 = 0x140
    double;	// 328 = 0x148
    CSAudioRecordContext *_recordContext;	// 336 = 0x150
    NSDate *_firstAudioPacketTimestamp;	// 344 = 0x158
    double _firstAudioSampleSensorTimestamp;	// 352 = 0x160
    unsigned long long _numSamplesProcessedBeforeAnchorTime;	// 360 = 0x168
    unsigned long long _anchorMachAbsTime;	// 368 = 0x170
    double _postVoiceTriggerSilence;	// 376 = 0x178
    long long _endpointerOperationMode;	// 384 = 0x180
    CSEnhancedEndpointer *_enhancedEndpointer;	// 392 = 0x188
    NSDictionary *_taskEnhancedEndpointerMap;	// 400 = 0x190
    NSDictionary *_enhancedEndpointerTaskThresholdMap;	// 408 = 0x198
}

- (void).cxx_destruct;	// IMP=0x00200000000d5399
@property(nonatomic) _Bool hasAcceptedEagerResult; // @synthesize hasAcceptedEagerResult=_hasAcceptedEagerResult;
@property(retain, nonatomic) NSDictionary *enhancedEndpointerTaskThresholdMap; // @synthesize enhancedEndpointerTaskThresholdMap=_enhancedEndpointerTaskThresholdMap;
@property(nonatomic) _Bool didReceiveRCFeatures; // @synthesize didReceiveRCFeatures=_didReceiveRCFeatures;
@property(nonatomic) _Bool enhancedEndpointerRelaxedResult; // @synthesize enhancedEndpointerRelaxedResult=_enhancedEndpointerRelaxedResult;
@property(nonatomic) _Bool enhancedEndpointerDefaultResult; // @synthesize enhancedEndpointerDefaultResult=_enhancedEndpointerDefaultResult;
@property(retain, nonatomic) NSDictionary *taskEnhancedEndpointerMap; // @synthesize taskEnhancedEndpointerMap=_taskEnhancedEndpointerMap;
@property(retain, nonatomic) CSEnhancedEndpointer *enhancedEndpointer; // @synthesize enhancedEndpointer=_enhancedEndpointer;
@property(nonatomic) long long endpointerOperationMode; // @synthesize endpointerOperationMode=_endpointerOperationMode;
@property(nonatomic) double postVoiceTriggerSilence; // @synthesize postVoiceTriggerSilence=_postVoiceTriggerSilence;
@property(nonatomic) _Bool didDetectSpeech; // @synthesize didDetectSpeech=_didDetectSpeech;
@property(nonatomic) _Bool recordingDidStop; // @synthesize recordingDidStop=_recordingDidStop;
@property(nonatomic) _Bool isASRFeatureFromServer; // @synthesize isASRFeatureFromServer=_isASRFeatureFromServer;
@property(nonatomic) _Bool isRequestTimeout; // @synthesize isRequestTimeout=_isRequestTimeout;
@property(nonatomic) _Bool isAnchorTimeBuffered; // @synthesize isAnchorTimeBuffered=_isAnchorTimeBuffered;
@property(nonatomic) unsigned long long anchorMachAbsTime; // @synthesize anchorMachAbsTime=_anchorMachAbsTime;
@property(nonatomic) unsigned long long numSamplesProcessedBeforeAnchorTime; // @synthesize numSamplesProcessedBeforeAnchorTime=_numSamplesProcessedBeforeAnchorTime;
@property(nonatomic) _Bool didTimestampFirstAudioPacket; // @synthesize didTimestampFirstAudioPacket=_didTimestampFirstAudioPacket;
@property(nonatomic) double firstAudioSampleSensorTimestamp; // @synthesize firstAudioSampleSensorTimestamp=_firstAudioSampleSensorTimestamp;
@property(retain, nonatomic) NSDate *firstAudioPacketTimestamp; // @synthesize firstAudioPacketTimestamp=_firstAudioPacketTimestamp;
@property(nonatomic) _Bool speechEndpointDetected; // @synthesize speechEndpointDetected=_speechEndpointDetected;
@property(retain, nonatomic) CSAudioRecordContext *recordContext; // @synthesize recordContext=_recordContext;
@property(nonatomic) _Bool didNotifyTwoShot; // @synthesize didNotifyTwoShot=_didNotifyTwoShot;
@property(nonatomic) double twoShotSilenceThresholdInMs; // @synthesize twoShotSilenceThresholdInMs=_twoShotSilenceThresholdInMs;
@property(nonatomic) double hepAudioOriginInMs; // @synthesize hepAudioOriginInMs=_hepAudioOriginInMs;
@property(nonatomic) unsigned long long vtEndInSampleCount; // @synthesize vtEndInSampleCount=_vtEndInSampleCount;
@property(nonatomic) double vtExtraAudioAtStartInMs; // @synthesize vtExtraAudioAtStartInMs=_vtExtraAudioAtStartInMs;
@property(nonatomic) unsigned long long currentRequestSampleRate; // @synthesize currentRequestSampleRate=_currentRequestSampleRate;
@property(nonatomic) _Bool didCommunicateEndpoint; // @synthesize didCommunicateEndpoint=_didCommunicateEndpoint;
@property(retain, nonatomic) NSObject<OS_dispatch_queue> *stateSerialQueue; // @synthesize stateSerialQueue=_stateSerialQueue;
@property(nonatomic) float lastEndpointPosterior; // @synthesize lastEndpointPosterior=_lastEndpointPosterior;
@property(nonatomic) double processedAudioInSeconds; // @synthesize processedAudioInSeconds=_processedAudioInSeconds;
@property(nonatomic) double lastReportedEndpointTimeMs; // @synthesize lastReportedEndpointTimeMs=_lastReportedEndpointTimeMs;
@property(retain, nonatomic) NSObject<OS_dispatch_queue> *hybridClassifierQueue; // @synthesize hybridClassifierQueue=_hybridClassifierQueue;
@property(retain, nonatomic) NSDictionary *taskThresholdMap; // @synthesize taskThresholdMap=_taskThresholdMap;
@property(nonatomic) unsigned long long extraDelayFrequency; // @synthesize extraDelayFrequency=_extraDelayFrequency;
@property(nonatomic) _Bool useDefaultServerFeaturesOnClientLag; // @synthesize useDefaultServerFeaturesOnClientLag=_useDefaultServerFeaturesOnClientLag;
@property(nonatomic) double clampedSFLatencyMsForClientLag; // @synthesize clampedSFLatencyMsForClientLag=_clampedSFLatencyMsForClientLag;
@property(nonatomic) double clientLagThresholdMs; // @synthesize clientLagThresholdMs=_clientLagThresholdMs;
@property(nonatomic) _Bool didReceiveServerFeatures; // @synthesize didReceiveServerFeatures=_didReceiveServerFeatures;
@property(retain, nonatomic) NSDate *lastServerFeatureTimestamp; // @synthesize lastServerFeatureTimestamp=_lastServerFeatureTimestamp;
@property(nonatomic) double serverFeaturesWarmupLatency; // @synthesize serverFeaturesWarmupLatency=_serverFeaturesWarmupLatency;
@property(nonatomic) _Bool epResult; // @synthesize epResult=_epResult;
@property(nonatomic) double lastKnownRCServerFeaturesLatency; // @synthesize lastKnownRCServerFeaturesLatency=_lastKnownRCServerFeaturesLatency;
@property(nonatomic) double lastKnowServerFeaturesLatency; // @synthesize lastKnowServerFeaturesLatency=_lastKnowServerFeaturesLatency;
@property(retain, nonatomic) NSMutableArray *serverFeatureLatencies; // @synthesize serverFeatureLatencies=_serverFeatureLatencies;
@property(retain, nonatomic) CSServerEndpointFeatures *lastKnownRCFeatures; // @synthesize lastKnownRCFeatures=_lastKnownRCFeatures;
@property(retain, nonatomic) OSDFeatures *lastKnownOSDFeatures; // @synthesize lastKnownOSDFeatures=_lastKnownOSDFeatures;
@property(retain, nonatomic) CSServerEndpointFeatures *lastKnownServerEPFeatures; // @synthesize lastKnownServerEPFeatures=_lastKnownServerEPFeatures;
@property(retain, nonatomic) NSObject<OS_dispatch_queue> *serverFeaturesQueue; // @synthesize serverFeaturesQueue=_serverFeaturesQueue;
@property(retain, nonatomic) NSString *endpointerModelVersion; // @synthesize endpointerModelVersion=_endpointerModelVersion;
@property(retain, nonatomic) _EAREndpointer *hybridClassifier; // @synthesize hybridClassifier=_hybridClassifier;
@property(retain, nonatomic) OSDFeatures *osdFeaturesAtEndpoint; // @synthesize osdFeaturesAtEndpoint=_osdFeaturesAtEndpoint;
@property(retain, nonatomic) CSAsset *currentAsset; // @synthesize currentAsset=_currentAsset;
@property(nonatomic) _Bool canProcessCurrentRequest; // @synthesize canProcessCurrentRequest=_canProcessCurrentRequest;
@property(nonatomic) _Bool saveSamplesSeenInReset; // @synthesize saveSamplesSeenInReset=_saveSamplesSeenInReset;
@property(nonatomic) double minimumDurationForEndpointer; // @synthesize minimumDurationForEndpointer=_minimumDurationForEndpointer;
@property(nonatomic) double automaticEndpointingSuspensionEndTime; // @synthesize automaticEndpointingSuspensionEndTime=_automaticEndpointingSuspensionEndTime;
@property(nonatomic) double delay; // @synthesize delay=_delay;
@property(nonatomic) double interspeechWaitTime; // @synthesize interspeechWaitTime=_interspeechWaitTime;
@property(nonatomic) double endWaitTime; // @synthesize endWaitTime=_endWaitTime;
@property(nonatomic) double startWaitTime; // @synthesize startWaitTime=_startWaitTime;
@property(nonatomic) long long endpointMode; // @synthesize endpointMode=_endpointMode;
@property(nonatomic) long long endpointStyle; // @synthesize endpointStyle=_endpointStyle;
@property(retain, nonatomic) NSString *mhId; // @synthesize mhId=_mhId;
@property(nonatomic) unsigned long long activeChannel; // @synthesize activeChannel=_activeChannel;
@property(nonatomic) __weak id <CSEndpointAnalyzerImplDelegate> implDelegate; // @synthesize implDelegate=_implDelegate;
@property(nonatomic) __weak id <CSEndpointAnalyzerDelegate> delegate; // @synthesize delegate=_delegate;
- (_Bool)_multimodalEndpointerEnabled;	// IMP=0x00100000000d4cfe
- (void)processRCFeatures:(id)arg1;	// IMP=0x00100000000d4c6e
- (_Bool)_useEnhancedEndpointer;	// IMP=0x00100000000d4c47
- (_Bool)_shouldProvideTwoShotFeedbackWithRecordContext;	// IMP=0x00100000000d4be6
- (id)_getCSHybridEndpointerConfigForAsset:(id)arg1;	// IMP=0x00100000000d4910
- (void)endpointerAssetManagerDidUpdateOSDAsset:(id)arg1;	// IMP=0x00100000000d490a
- (void)endpointerAssetManagerDidUpdateAsset:(id)arg1;	// IMP=0x00100000000d487a
@property(readonly, nonatomic) double lastStartOfVoiceActivityTime;
@property(readonly, nonatomic) double lastEndOfVoiceActivityTime;
- (void)getFirstAudioSampleSensorHostTimeWithReply:(CDUnknownBlockType)arg1;	// IMP=0x00100000000d4856
- (void)reset;	// IMP=0x00100000000d4850
- (void)_readParametersFromHEPAsset:(id)arg1;	// IMP=0x00100000000d47c0
- (void)resetForNewRequestWithSampleRate:(unsigned long long)arg1 recordContext:(id)arg2;	// IMP=0x00100000000d43e6
- (void)stopEndpointer;	// IMP=0x00100000000d4350
- (void)recordingStoppedForReason:(long long)arg1;	// IMP=0x00100000000d42a8
- (void)terminateProcessing;	// IMP=0x00100000000d41e1
- (void)preheat;	// IMP=0x00100000000d41db
- (void)handleVoiceTriggerWithActivationInfo:(id)arg1;	// IMP=0x00100000000d414a
- (void)logFeaturesWithEvent:(id)arg1 locale:(id)arg2;	// IMP=0x00100000000d4090
- (void)_generateEndpointerFeaturesWithEffectiveClientProcessedAudioMs:(double)arg1 osdFeatures:(id)arg2 completion:(CDUnknownBlockType)arg3;	// IMP=0x00100000000d36b9
- (void)processOSDFeatures:(id)arg1 withFrameDurationMs:(double)arg2;	// IMP=0x00100000000d31f7
- (void)processFirstAudioPacketTimestamp:(id)arg1 firstAudioSampleSensorTimestamp:(unsigned long long)arg2;	// IMP=0x00100000000d3153
- (void)logAnchorMachAbsTime:(unsigned long long)arg1 numSamplesProcessedBeforeAnchorTime:(unsigned long long)arg2 isAnchorTimeBuffered:(_Bool)arg3;	// IMP=0x00100000000d30f8
- (void)_shouldAcceptEagerResultForDuration:(double)arg1 serverFeatures:(id)arg2 lastReportedEndpointTimeMs:(double)arg3 osdFeatures:(id)arg4 resultsCompletionHandler:(CDUnknownBlockType)arg5;	// IMP=0x00100000000d2afc
- (void)shouldAcceptEagerResultForDuration:(double)arg1 resultsCompletionHandler:(CDUnknownBlockType)arg2;	// IMP=0x00100000000d29bb
- (void)shouldAcceptEagerResultForDuration:(double)arg1 withEndpointerMetrics:(id)arg2 resultsCompletionHandler:(CDUnknownBlockType)arg3;	// IMP=0x00100000000d286e
- (_Bool)shouldAcceptEagerResultForDurationSync:(double)arg1 withEndpointerMetrics:(id)arg2;	// IMP=0x00100000000d26e4
- (void)processServerEndpointFeatures:(id)arg1;	// IMP=0x00100000000d24bd
- (void)_swapEnhancedEndpointerModelForTaskString:(id)arg1;	// IMP=0x00100000000d21e3
- (void)_processEnhancedEndpointerTaskString:(id)arg1;	// IMP=0x00100000000d1ea5
- (void)processTaskString:(id)arg1;	// IMP=0x00100000000d1e15
- (void)processASRFeatures:(id)arg1 fromServer:(_Bool)arg2;	// IMP=0x00100000000d1d87
- (long long)fetchCurrentEndpointerOperationMode;	// IMP=0x00100000000d1cf8
- (void)updateEndpointerDelayedTrigger:(_Bool)arg1;	// IMP=0x00100000000d1bc6
- (void)_updateEndpointerDelayedTriggerByMhId:(id)arg1;	// IMP=0x00100000000d1acc
- (void)updateEnhancedEndpointerDefaultThresholdPartial:(float)arg1 defaultThresholdRC:(float)arg2 relaxedThresholdPartial:(float)arg3 relaxedThresholdRC:(float)arg4;	// IMP=0x00100000000d19db
- (void)updateEndpointerThreshold:(float)arg1;	// IMP=0x00100000000d1988
- (void)processAudioSamplesAsynchronously:(id)arg1;	// IMP=0x00100000000d1982
- (id)_getSerialQueueWithName:(id)arg1 targetQueue:(id)arg2;	// IMP=0x00100000000d1892
- (id)init;	// IMP=0x00100000000d140b

// Remaining properties
@property(nonatomic) double bypassSamples;
@property(readonly, copy) NSString *debugDescription;
@property(readonly, copy) NSString *description;
@property(readonly) unsigned long long hash;
@property(readonly) Class superclass;

@end

